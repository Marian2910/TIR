% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
\usepackage{cite}

\usepackage{float}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
% \usepackage[super, square]{natbib}

\usepackage[dvipsnames]{xcolor}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    citecolor=CadetBlue,
    filecolor=CadetBlue,      
    urlcolor=CadetBlue,
}
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
\urlstyle{rm}
%
\usepackage{longtable}


\begin{document}

\title{Survey on Energy Consumption Optimization Approach in Container-Based Cloud Environments}
\titlerunning{Energy Optimization in Container-Based Cloud Environments}


\author{Francesco Pace Napoleone\inst{1} \and
Marian-Catalin Mutu-Costan\inst{1} \and
Ihor Ryzhuk\inst{1} \and
Ewan Soueidan\inst{1}}

\authorrunning{F. Pace Napoleone et al.}

\institute{Université de Toulouse, France \\
\email{\{francesco.pace-napoleone, marian.mutu-costan, ihor.ryzhuk, ewan.soueidan\}@univ-tlse3.fr}}

\maketitle
%
\begin{abstract}

Growing demand for cloud services has shifted data center design from performance-centric to energy-efficient architectures. Containerization, a lightweight alternative to virtual machine, enables flexible resource allocation and reduced overhead. This survey reviews energy optimization techniques in container-based cloud environments by systematically selecting studies from 2010-2020 and categorizing them by scheduling scope, optimization method, energy-saving strategy, and Docker maturity. Our analysis covers early VM consolidation methods that achieved up to 83\% energy savings, predictive scheduling, and advanced container orchestration. Overall, container-based optimizations, particularly those leveraging AI and hybrid heuristics, significantly reduce energy consumption while maintaining Quality of Service (QoS), pointing to promising future research directions.

\keywords{Cloud Computing \and Containerization \and Energy Optimization \and Microservices \and Resource Allocation}
\end{abstract}

\section{Introduction}
\subsection{From Monoliths to Containers: Energy Implications}
Cloud computing evolved to support scalable platform usage, moving from single-file applications to client/server 
architectures with monolithic backends, then to microservices with containers, and now transitioning to micro-frontends. 
Containers run directly on the host using Linux CGroups, bypassing the hypervisor overhead inherent in VMs (e.g., 
Proxmox, VMWare), which allows for full utilization of host CPU resources and simplifies telemetry monitoring. 
This lightweight nature is evident in Docker files that simply copy files and run builds, making containers easier to integrate 
into CI/CD pipelines.

However, this increased reliance on cloud-based infrastructures has led to a significant rise in energy 
consumption. In 2006, the electricity costs for IT infrastructures in the United States alone were 
estimated at \$4.5 billion\cite{beloglazov_energy_2010}. Energy consumption optimization has since become a 
critical concern, especially as cloud data centers now account for approximately 1-1.5\% of global 
electricity use\cite{IEADataCentres}. Despite efficiency improvements, the demand for digital 
services continues to grow, pushing the need for more sustainable solutions.

\subsection{Energy-Aware Containerized Cloud Environments}
As energy consumption in cloud infrastructures continues to rise, optimizing energy efficiency through 
containerized environments has become increasingly important. Early research focused on heuristic-based 
approaches to optimize virtual machine (VM) placement, achieving 
energy savings of up to 83\% while maintaining only a 1.1\% service level agreement (SLA) violation 
rate\cite{beloglazov_energy_2010}. More recently, research has shifted from VM-based allocation towards 
containerized environments, where energy efficiency is influenced by scheduling strategies, workload 
distribution, and infrastructure optimizations. 

The paper ``Survey on Energy Consumption Optimization Approach in Container Based Cloud Environments'' 
further highlights that containerization not only drives scalability and 
reproducibility but also plays a crucial role in optimizing energy consumption. It 
explores strategies for efficient resource allocation, reducing power overhead, and 
ensuring that the benefits of container-based deployments extend beyond performance 
to sustainability in cloud infrastructures.
In this work, we present a state-of-the-art review on Energy Consumption Optimization Approaches in 
Container-Based Cloud Environments. Our survey of the available literature—predominantly spanning 
from 2010 to 2020—reveals that foundational research primarily focused on energy measurement, 
basic optimization strategies, and energy visualization techniques\cite{beloglazov_energy_2010}.

\section{Literature Review Approach}
The research process began by defining our scope together with our supervisor, Professor Jean-Marc Pierson. We focused on creating a state-of-the-art review 
addressing energy consumption optimization within Container and Cloud Computing.

Initially, we defined a structured ``Search Pipeline'' illustrated in Figure~\ref{fig:search_pipeline}, ensuring systematic identification and evaluation of relevant papers.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\columnwidth]{flowchartTIR.png}
    \caption{Search Pipeline Flowchart}\label{fig:search_pipeline}
\end{figure}

We developed an initial search query: \textit{((energy OR resource) AND container)}, including ``resource'' to account for better resource utilization directly influencing energy efficiency.

Clear exclusion criteria were established beforehand (Table~\ref{tab:Exclusion Rules}), filtering out irrelevant work and focusing exclusively on impactful research.
\begin{table}[H]
\centering
\begin{tabular}{c}
\hline
Direct Exclusion of Paper If \\ \hline
Work is not in English \\ 
Work is not a scientific paper \\ 
Work has fewer than 10 citations \\ 
Work is not related to containers/cloud \\ \hline
\end{tabular}
    \caption{Exclusion Criteria}
    \label{tab:Exclusion Rules}
\end{table}

This approach yielded 34 relevant papers, sourced across various publishers, as depicted in Figure~\ref{fig:exported_papers}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\columnwidth]{exportedPapers.png}
    \caption{Distribution of Exported Papers by Publisher}\label{fig:exported_papers}
\end{figure}

The majority of selected studies were published between 2017 and 2019 (Figure~\ref{fig:papers_per_year}), reflecting a peak period of research interest.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\columnwidth]{papers_per_year.png}
    \caption{Papers per Year}\label{fig:papers_per_year}
\end{figure}

After paper selection, we defined specific classification metrics (Table~\ref{tab:Paper Classification}) to analyze the technical dimensions of energy-aware scheduling approaches.

\begin{table}[H]
\centering
\begin{tabular}{c}
\hline
Classification Categories\\ \hline
Optimization Technique \\ 
Target Level  \\ 
Scheduling Scope \\ 
Energy Strategy \\
Docker Awareness \\
\hline
\end{tabular}
    \caption{Paper Classification Metrics}
    \label{tab:Paper Classification}
\end{table}

The classification categories are defined as follows:
\begin{itemize}
  \small
  \item \textbf{Scheduling Scope}
    \begin{itemize}
      \item \textbf{Online}: Decisions at runtime.
      \item \textbf{Offline}: Known workload beforehand.
      \item \textbf{Predictive}: Forecast-based decisions.
      \item \textbf{Reactive}: Triggered by SLA violations or thresholds.
      \item \textbf{Concurrent}: Simultaneous multiple-task scheduling.
    \end{itemize}

  \item \textbf{Optimization Technique}
    \begin{itemize}
      \item \textbf{Greedy}: Stepwise local decisions.
      \item \textbf{Model-Based}: Predictive analytical models.
      \item \textbf{PSO}: Bio-inspired global optimization.
      \item \textbf{Evolutionary}: Genetic/evolution-based methods.
      \item \textbf{Meta-Heuristic}: High-level heuristic strategies.
      \item \textbf{MCMF}: Flow-network optimization.
    \end{itemize}

  \item \textbf{Energy Strategy}
    \begin{itemize}
      \item \textbf{Consolidation}: Migrate to reduce active hosts.
      \item \textbf{Brownout}: Temporarily disable app components.
      \item \textbf{QoS Maintenance}: Energy-saving without SLA violations.
      \item \textbf{Renewable-aware}: Optimize for renewable energy availability.
    \end{itemize}

  \item \textbf{Docker Awareness}
    \begin{itemize}
      \item \textbf{Pre-Docker}: Pre-containerization (VM-only).
      \item \textbf{Early Docker}: Containers used like VMs.
      \item \textbf{Mature Docker}: Container-specific optimizations.
    \end{itemize}
\end{itemize}

We incorporated \textbf{Docker Awareness} to highlight the technological transition from virtual machines to containers, essential for understanding changes in scheduling complexity. \textbf{Energy Awareness} is included to represent approaches' capability to balance energy efficiency with QoS constraints, recognizing the different trade-offs between performance and sustainability.

Finally, Tables~\ref{tab:technical_papers} and \ref{tab:surveys} summarize our classified selection, and Figure~\ref{fig:trend_analysis} visually correlates scheduling approaches with their publication years.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{Trend_Analysis.jpeg}
    \caption{Trend Analysis}
    \label{fig:trend_analysis}
\end{figure}

\begin{footnotesize}
\begin{longtable}{|p{3.8cm}|p{2.3cm}|p{1.6cm}|p{2.3cm}|p{2.2cm}|p{2cm}|}
\hline
\textbf{Paper Ref.} & \textbf{Optimization Technique} & \textbf{Target Level} & \textbf{Scheduling Scope} & \textbf{Energy Strategy} & \textbf{Docker Awareness} \\
\hline
\endfirsthead

\hline
\textbf{Paper Ref.} & \textbf{Optimization Technique} & \textbf{Target Level} & \textbf{Scheduling Scope} & \textbf{Energy Strategy} & \textbf{Docker Awareness} \\
\hline
\endhead
Availability-Aware Scheduler\cite{alahmad_availability-aware_2018} (2018) & Greedy & Container, VM & Offline & Availability & Mature Docker\\
\hline
Renewable-Aware Scheduling\cite{kumar_renewable_2019} (2019)& Greedy & Container, VM & Reactive & Consolidation & Mature Docker \\
\hline
Concurrent Container Scheduling\cite{hu_concurrent_2020} (2020)& MCMF & Container & Concurrent & Consolidation & Mature Docker \\
\hline
GP Hyper-Heuristic for Containers\cite{tan_hybrid_2019} (2019)& Evolutionary & Container, VM & Online & Consolidation & Mature Docker \\
\hline
PSO-Based Container Consolidation\cite{shi_energy-aware_2018} (2018)& PSO & Container & Offline & Consolidation & Mature Docker \\
\hline
Energy-Efficient Container Framework\cite{piraghaj_framework_2015} (2015)& Greedy & Container, VM & Reactive & Consolidation & Early Docker \\
\hline
VM Consolidation Strategy\cite{carrega_energy-aware_2017} (2017)& Meta-Heuristic & VM & Online & Consolidation & Mature Docker \\
\hline
Predictive Resource Provisioning\cite{dabbagh_energy-efficient_2015} (2015)& Model-based  & VM & Predictive & Consolidation & Early-Docker \\
\hline
Dynamic VM Reallocation\cite{beloglazov_energy_2010} (2010) & Greedy & VM & Online & Consolidation & Pre-Docker \\
\hline
Autonomic Container Management\cite{barna_delivering_2017} (2017) & Model-based & Container, VM & Predictive & QoS & Mature Docker \\
\hline
Brownout-Based Scheduling\cite{xu_energy_2016} (2016)& Greedy & Application Layer & Reactive & Brownout & Mature Docker \\
\hline
GPR + Convex VM Planning\cite{bui_energy_2017} (2017) & Model-Based & VM, PM & Predictive & Consolidation & Mature Docker \\
\hline
SLA-Aware Consolidation\cite{li_sla-aware_2018} (2018) & Model-Based & VM, PM & Predictive & Consolidation & Mature Docker \\
\hline
\caption{Classification of Technical Papers on Energy-Aware Scheduling}
\label{tab:technical_papers}
\end{longtable}
\end{footnotesize}

\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{|p{5.5cm}|p{3.5cm}|p{4cm}|}
\hline
\textbf{Paper Ref.} & \textbf{Type} & \textbf{Scope / Focus} \\
\hline
Survey on Energy-Aware Scheduling\cite{hameed_survey_2016}  & Survey & Overview of VM and container-level techniques \\
\hline
Global Energy Estimates\cite{masanet_2020} & Analysis & Environmental impact of data centers \\
\hline
Cloud Impact on Energy\cite{hintemann_2022} & Report & Energy use in European data centers \\
\hline
IEA Report on Data Centers\cite{IEADataCentres} & Report & Global energy trends in ICT and data centers \\
\hline
EU Data Center Energy Trends\cite{avgerinou_trends_2017} & Analysis & EU-level trends in ICT energy consumption \\
\hline
\end{tabular}
\caption{Survey and Analysis Papers}
\label{tab:surveys}
\end{table}

\section{Trend reconstruction}

\subsection{Early approaches}

Early efforts in energy-aware cloud infrastructure trace back to 2010, with Docker’s release in 2013 marking a pivotal point for containerization. Even earlier, in 2006, electricity consumption by IT infrastructure in the US was estimated at \$4.5 billion and projected to double by 2011\cite{beloglazov_energy_2010}. These cost concerns initiated research into energy-efficient resource management.

Initial studies, such as by Beloglazov and Buyya\cite{beloglazov_energy_2010}, applied bin packing heuristics with dynamic voltage and frequency scaling (DVFS) using the CloudSim simulator. Their methods achieved energy savings of up to 83\% while maintaining SLA violation rates under 1.1\%, laying the foundation for dynamic VM consolidation strategies.

By 2015, the research focus shifted toward predictive modeling to overcome the rigidity of static thresholding. Dabbagh et al.\cite{dabbagh_energy-efficient_2015} introduced a Wiener filter-based workload predictor alongside Best Fit Decreasing allocation. This approach improved energy efficiency by up to 33\% over heuristic methods.

In 2017, Bui et al.\cite{bui_energy_2017} advanced this with Gaussian Process Regression (GPR) for non-stationary workload prediction, optimized using the Fast Fourier Transform. Coupled with convex optimization for VM migration, this approach achieved 35\% energy savings, with only a modest 15\% latency increase. 

In parallel, other strategies emerged: brownout-based scheduling\cite{xu_energy_2016}, SLA-aware provisioning\cite{li_sla-aware_2018}, and energy-visualization frameworks, all contributing to a broader, more nuanced approach to energy optimization\cite{carrega_energy-aware_2017, hameed_survey_2016}.

\subsection{From Virtual Machines to Containers}

As the field matured, attention shifted from VM-centric models toward container-based deployments. Containers offer lower overhead, faster startup times, and better resource packing, enabling finer-grained resource management compared to traditional VMs\cite{alahmad_availability-aware_2018}.

Early contributions in this space, such as those by Piraghaj et al.\cite{piraghaj_framework_2015}, explored container consolidation for energy savings. Later, more sophisticated methods emerged. Alahmad et al.\cite{alahmad_availability-aware_2018} introduced availability-aware scheduling using modular watchdogs and Pearson correlation for anomaly detection. Hu et al.\cite{hu_concurrent_2020} proposed framing container scheduling as a minimum-cost flow problem, scalable to over 5000 nodes.

Tan et al.\cite{tan_hybrid_2019} combined evolved genetic heuristics with human-designed rules to solve two-level placement (container to VM, VM to host), accounting for reliability metrics like MTTF and MTTR. These hybrid systems improved both energy efficiency and fault tolerance.

Meanwhile, broader infrastructure-aware techniques appeared. Renewable-aware scheduling\cite{kumar_renewable_2019}, optimization-based container consolidation\cite{shi_energy-aware_2018}, and DevOps-driven elastic container management\cite{barna_delivering_2017} highlighted the expanding scope of energy-centric design.

\subsection{Recent Shifts and Outlook}

Beyond technical scheduling innovations, researchers increasingly examine broader systemic and policy-level trends. Studies like those by Avgerinou et al.\cite{avgerinou_trends_2017} emphasize the macro-scale impact of data center energy use, while recent data from IEA and Masanet et al.\cite{masanet_2020, hintemann_2022, IEADataCentres} suggest a growing need for integrated, user-centric energy management systems.

This evolution—from basic heuristics and VM scheduling to hybrid AI-driven, reliability-aware container systems—reflects a maturing field. The latest focus centers on adaptability, sustainability, and predictive intelligence, paving the way for resilient, energy-optimized cloud ecosystems.

\section{Method Analysis}

\subsection{Methodology}

Over time, different researchers have utilized various testing environments and hardware configurations to evaluate their energy-aware scheduling algorithms. To examine the evolution of their experimental approaches, we have collected and structured data from the selected papers, focusing on the simulation environment, the number of CPU Cores, memory capacity, and power consumption of the experimentation hardware. Specifically, we define:

\begin{itemize}
    \footnotesize
    \item \textbf{P idle (W)} as the power consumption at low CPU utilization (generally below 50\% load).
    \item \textbf{P max (W)} as the power consumption at maximum CPU load.
\end{itemize}

In some studies, multiple hardware configurations were reported—either due to hardware availability or to assess performance on more powerful setups. In these cases, multiple entries are provided in the table. Note that when power consumption figures were not experimentally reported but instead obtained from hardware specification (by searching for the make and model), those values are marked with an asterisk (\textasteriskcentered). Whenever certain data fields were omitted by the authors, we use ``Nm'' (not mentioned).

\begin{footnotesize}
\begin{longtable}{|p{3.8cm}|p{2.2cm}|p{1.2cm}|p{1.5cm}|p{1.8cm}|p{1.8cm}|}
\hline
\textbf{Paper Ref.} & \textbf{Simulation Environment} & \textbf{CPU Cores} & \textbf{Memory (GB)} & \textbf{Power P idle (W)} & \textbf{Power P max (W)} \\
\hline
\endfirsthead

\hline
\textbf{Paper Ref.} & \textbf{Simulation Environment} & \textbf{CPU Cores} & \textbf{Memory (GB)} & \textbf{Power P idle (W)} & \textbf{Power P max (W)} \\
\hline
\endhead
Availability-Aware Scheduler \cite{alahmad_availability-aware_2018} (2018) & CloudSim & Nm & Nm & Nm & Nm \\
\hline
Renewable-Aware Scheduling \cite{kumar_renewable_2019} (2019) & Nm & 4 & 64 & 100 & 150 \\
\hline
Renewable-Aware Scheduling \cite{kumar_renewable_2019} (2019) & Nm & 8 & 128 & 120 & 200 \\
\hline
Renewable-Aware Scheduling \cite{kumar_renewable_2019} (2019) & Nm & 16 & 256 & 150 & 250 \\
\hline
Concurrent Container Scheduling \cite{hu_concurrent_2020} (2020) Homogeneous Cluster & ExoGENI & 2 & 6 & Nm & Nm \\
\hline
Concurrent Container Scheduling \cite{hu_concurrent_2020} (2020) & ExoGENI & 1 & 3 & Nm & Nm \\
\hline
Concurrent Container Scheduling \cite{hu_concurrent_2020} (2020) & ExoGENI & 2 & 6 & Nm & Nm \\
\hline
Concurrent Container Scheduling \cite{hu_concurrent_2020} (2020) & ExoGENI & 4 & 12 & Nm & Nm \\
\hline
GP Hyper-Heuristic for Containers \cite{tan_hybrid_2019} (2019) & Nm & Nm & 0.8 & Nm & Nm \\
\hline
PSO-Based Container Consolidation \cite{shi_energy-aware_2018} (2018) & Nm & 4 & 16 & Nm & Nm \\
\hline
Energy-Efficient Container Framework \cite{piraghaj_framework_2015} & CloudSim & 4 & 64 & 86 & 117 \\
\hline
Energy-Efficient Container Framework \cite{piraghaj_framework_2015} & CloudSim & 8 & 128 & 93 & 135 \\
\hline
Energy-Efficient Container Framework \cite{piraghaj_framework_2015} & CloudSim & 16 & 256 & 66 & 247 \\
\hline
VM Consolidation Strategy \cite{carrega_energy-aware_2017} (2017) & Nm & 2 & Nm & 170 & 220 \\
\hline
Predictive Resource Provisioning \cite{dabbagh_energy-efficient_2015} (2015) & Nm & Nm & Nm & 107 & 300.81 \\
\hline
Dynamic VM Reallocation \cite{beloglazov_energy_2010} (2010) & Nm & 1 & 8 & Nm & Nm \\
\hline
Autonomic Container Management \cite{barna_delivering_2017} (2017) & LEGIS & Nm & 16 & Nm & Nm \\
\hline
Brownout-Based Scheduling \cite{xu_energy_2016} & CloudSim & 2 & 4 & 156\textasteriskcentered & 247\textasteriskcentered \\
\hline
GPR + Convex VM Planning \cite{bui_energy_2017} (2017) & Nm & 4 & 12 & 225\textasteriskcentered & 375\textasteriskcentered \\
\hline
SLA-Aware Consolidation \cite{li_sla-aware_2018} (2018) & CloudSim & 2 & 4 & 102 & 117 \\
\hline
SLA-Aware Consolidation \cite{li_sla-aware_2018} (2018) & CloudSim & 2 & 4 & 116 & 135 \\
\hline
\caption{Hardware and Power Specifications}
\label{tab:hardware_specs}
\end{longtable}
\end{footnotesize}

\subsection{Plots and Visualization}

We visualized the simulation environments used in each paper over time to observe how they have evolved (Figure~\ref{fig:timeline}). Each point corresponds to a paper, placed according to its publication year and the simulation platform it utilized (CloudSim, ExoGENI, LEGIS, or ``Nm'' if not mentioned) Each point denotes a paper, positioned by its publication year and the simulation platform it utilized.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\columnwidth]{Timeline.png}
    \caption{Timeline of simulation environments used in each paper (2010--2020). }
    \label{fig:timeline}
\end{figure}

Additionally, we plotted the relationship between the number of CPU cores and the \textit{energy delta} (the difference $P_{\max} - P_{\begin{footnotesize}idle \end{footnotesize}}$), shown in Figure~\ref{fig:energy_delta}. This second figure highlights how dynamic power consumption scales with increased core counts and is further distinguished by algorithm type (color) and simulation environment (marker shape).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\columnwidth]{Energy.png}
    \caption{2D Scatter Plot: CPU cores vs. Energy Delta $(P_{\max} - P_{\begin{footnotesize}idle\end{footnotesize}})$.}
    \label{fig:energy_delta}
\end{figure}

\section{Conclusions}

Energy consumption optimization in container-based cloud environments has evolved from early heuristic methods to sophisticated, predictive, and container-aware scheduling approaches. Early consolidation techniques demonstrated significant energy savings through aggressive host shutdown and DVFS, but their reliance on static thresholds often limited adaptability under dynamic workloads\cite{carrega_energy-aware_2017}. In contrast, predictive algorithms that incorporate workload forecasting and dynamic resource allocation have achieved further energy reductions (typically 30--35\%) while balancing the trade-off between energy savings and service quality\cite{dabbagh_energy-efficient_2015,bui_energy_2017}.

The transition from VM-based to container-based solutions has enabled finer-grained resource management, with approaches such as flow-network optimization for container placement proving effective even in large-scale simulations\cite{hu_concurrent_2020}. Additionally, strategies like brownout scheduling\cite{xu_energy_2016} and meta-heuristic or AI-driven methods\cite{tan_hybrid_2019,shi_energy-aware_2018} have shown promise in achieving global optimization over complex infrastructures, albeit with increased computational overhead.

A key insight from the surveyed literature is that no single method outperforms all others under every scenario; instead, each approach excels in specific operational contexts. For instance, consolidation-focused strategies yield high energy savings but require careful management to avoid SLA violations, whereas QoS-aware methods maintain performance at the expense of some energy efficiency\cite{li_sla-aware_2018}. Moreover, the emerging integration of renewable energy awareness into scheduling algorithms\cite{kumar_renewable_2019} points toward a future where energy management is not only efficient but also environmentally sustainable.

Looking ahead, future research should aim to integrate these diverse techniques into hybrid frameworks that combine predictive scheduling, dynamic consolidation, and real-time QoS monitoring. This integration, alongside the continued evolution of container orchestration platforms, is essential for achieving the dual goals of operational efficiency and sustainable cloud computing.

\bibliographystyle{splncs04}
\bibliography{references}

\end{document}
